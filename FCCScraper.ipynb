{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfminer as pm\n",
    "import math\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta  \n",
    "import warnings\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(p1t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in all table regions\n",
    "def convertPDFToTable(filepath):\n",
    "    table_cols = [['35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550'], \n",
    "                  ['44,']]\n",
    "    curColSetting = 0\n",
    "    p1t = camelot.read_pdf(filepath, \n",
    "                         strip_text=' .\\n', flavor='stream', pages=\"1-end\",\n",
    "                         #table_regions=['0,700,600,0'],\n",
    "                          columns=table_cols[curColSetting], \n",
    "                           edge_tol=75)\n",
    "    pdf = []\n",
    "    for t in p1t:\n",
    "        pdf.append(t.df)\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTables(tables, committee, station):\n",
    "    progColName=False\n",
    "    ## Create the ad day/times df.\n",
    "    ads = pd.DataFrame(columns=['StartDate', 'EndDate', 'Weekdays', 'Spots/Week', 'Rate', 'Rating', 'index'])\n",
    "    ## Create the shows DF.\n",
    "    shows = pd.DataFrame(columns=['index', 'Title'])\n",
    "    secondlines = pd.DataFrame(columns=['index', 'Title'])\n",
    "    ## Add second line of inventory code\n",
    "    def mergeSLines(row):\n",
    "        if row.name+1 < len(shows):\n",
    "            nextRow = shows.iloc[row.name+1]\n",
    "            sline = secondlines[(row['index'] < secondlines['index']) & (nextRow['index']>secondlines['index'])]\n",
    "        else: \n",
    "            sline = secondlines[(row['index'] < secondlines['index'])]\n",
    "        if(len(sline)>0):\n",
    "            if(row['Title'] != sline['Title'].values[0]):\n",
    "                row['Title'] = row['Title'] + sline['Title'].values[0]\n",
    "        else:\n",
    "            print('Second line merge error at ad: ', row.name)\n",
    "        return row\n",
    "    \n",
    "    def getSecondLines(df):\n",
    "        returnVal = pd.DataFrame(columns=['index', 'Title'])\n",
    "        #Get show lines\n",
    "        progs = df[(df['Amount'] != '') & (df['Ch'] != '')]\n",
    "        progs = progs.iloc[1:] # Remove residual header row.\n",
    "        slines = list(map(lambda x: x+1, progs.index.values))\n",
    "        if not (slines[-1] < len(df)): ## In case the second show line is on the next page.\n",
    "            print('Program second line on next page.')\n",
    "            slines = slines[:-1]\n",
    "        slines = df.iloc[slines]\n",
    "        slines = slines.replace('', np.nan, regex=True)\n",
    "        slines = slines[slines.isnull().sum(axis=1) == len(slines.columns)-1]\n",
    "        for index, row in slines.iterrows():\n",
    "            nulls = pd.isnull(row)\n",
    "            nulls = nulls[nulls!=True]\n",
    "            returnVal = returnVal.append({'index': index, 'Title': row[nulls.index[0]]}, ignore_index=True)\n",
    "        returnVal['index'] = returnVal['index'] + lastIndex\n",
    "        return returnVal\n",
    "    def addNameIfDiff(p):\n",
    "        for val in nlines.iloc[p.name]:\n",
    "            if(p[progColName] != val) & (val.isna() != True):\n",
    "                p[progColName] = p[progColName] + val\n",
    "        return p\n",
    "    ## Merge program names into ad days.\n",
    "    def mergeProgs(i):\n",
    "        p = shows[shows['index']<=i]\n",
    "        p = p.iloc[len(p)-1]\n",
    "        return p['Title']\n",
    "    ## Create individual records for each ad spot.  \n",
    "    ## Filter out day times rows.                \n",
    "    def getDays(row):\n",
    "        #print(row)\n",
    "        nextRow = 1\n",
    "        dayCols = ['StartDate', 'EndDate', 'Weekdays', 'Spots/Week', 'Rate']\n",
    "        for val in row:\n",
    "            try:\n",
    "                ind = dayCols.index(val)\n",
    "                dayCols.remove(val)\n",
    "            except:\n",
    "                pass\n",
    "        if(len(dayCols) == 0):\n",
    "            if(len(headers)==0):\n",
    "                headers.append(row.name)\n",
    "            while (nextRow!=-1):\n",
    "                dayColFound=False\n",
    "                if((row.name+nextRow) != len(buys)):\n",
    "                    for k in buys.loc[(row.name+nextRow), :]:\n",
    "                        if k == 'Week:':\n",
    "                            headers.append((row.name+nextRow))\n",
    "                            nextRow=nextRow+1\n",
    "                            dayColFound=True\n",
    "                    if dayColFound!=True:\n",
    "                        nextRow=-1\n",
    "                else:\n",
    "                    nextRow=-1\n",
    "    def findHeaderRow(row):\n",
    "        headers =  { 'Type1': ['StartDateEndDateDescription'],\n",
    "                     'Type2': ['Amount', 'Start', 'InventoryCode', 'Rate', 'Spots'] }\n",
    "        for htype in headers:\n",
    "            for val in row:\n",
    "                try:\n",
    "                    ind = headers[htype].index(val)\n",
    "                    headers[htype].remove(val)\n",
    "                except:\n",
    "                    pass\n",
    "        if(len(headers['Type1']) == 0):\n",
    "            return ['Description', row.name]\n",
    "        else:\n",
    "            if(len(headers['Type2']) == 0):\n",
    "                return ['InventoryCode', row.name]\n",
    "    def fixHeaders(row):\n",
    "        fixCol = -1\n",
    "        for k in row.keys():\n",
    "            if row[k] == 'StartDateEndDateDescription':\n",
    "                fixCol = k\n",
    "        if fixCol != -1:\n",
    "            if(fixCol == 3):\n",
    "                row[(fixCol-2)] = 'Ch'\n",
    "                row[(fixCol-1)] = 'Start'\n",
    "                row[(fixCol)] = 'End'\n",
    "                row[(fixCol+1)] = 'Description'\n",
    "                row[(fixCol+2)] = 'Desc2'\n",
    "            if(fixCol == 2):\n",
    "                row[(fixCol)] = 'Start'\n",
    "                row[(fixCol+1)] = 'End'\n",
    "                row[(fixCol+2)] = 'Description'\n",
    "        return row\n",
    "    ## Filter out program names.\n",
    "    lastIndex = 0\n",
    "    for t in tables:\n",
    "        progColName=False\n",
    "        headerConfig = t.apply(findHeaderRow, axis=1).dropna()\n",
    "        if len(headerConfig)>0:\n",
    "            progColName = headerConfig.values[0][0]\n",
    "        if progColName != False:\n",
    "            ## Figure out inventory code lines\n",
    "            progs = t.copy()\n",
    "            if progColName == 'Description':\n",
    "                progs = progs.apply(fixHeaders, axis=1)\n",
    "                progs.columns = progs.iloc[headerConfig.values[0][1]]\n",
    "            else:\n",
    "                progs.columns = progs.iloc[headerConfig.values[0][1]]\n",
    "            progs = progs.iloc[headerConfig.values[0][1]:]\n",
    "            progs = progs.reset_index(drop=True)\n",
    "            \n",
    "            ## Some WideOrbit reports have two line program names, this gets the second lines.\n",
    "            if progColName == 'InventoryCode':\n",
    "                slines = getSecondLines(progs)\n",
    "                secondlines = secondlines.append(slines)\n",
    "            ## Get the program name rows\n",
    "            progs = progs[(progs['Amount'] != '') & (progs['Ch'] != '')] \n",
    "            progs = progs.iloc[1:] # Remove residual header row.\n",
    "            if progColName == 'Description':\n",
    "                progs['Description'] = progs['Description'] + progs['Desc2']\n",
    "            progs = progs.reset_index()\n",
    "            ## Make index run continously accross pages.\n",
    "            progs['index'] = progs['index'] + lastIndex\n",
    "            lastIndex = t.iloc[len(t)-1].name+lastIndex+1\n",
    "            ## Remove duplicate columns and append to the master list.\n",
    "            progs = progs.loc[:,~progs.columns.duplicated()]\n",
    "            progs = progs.rename(columns={progColName:'Title'})\n",
    "            progs = progs[['index', 'Title']]\n",
    "            shows = shows.append(progs)\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"False\")\n",
    "    ## Merge in the second lines to complete the program names.\n",
    "    if progColName == 'InventoryCode':\n",
    "        shows = shows.reset_index(drop=True)\n",
    "        shows = shows.apply(mergeSLines, axis=1)\n",
    "    ## Seperate out the days and times each ad will be on.\n",
    "    lastIndex = 0\n",
    "    for t in tables:\n",
    "        progColName=False\n",
    "        headerConfig = t.apply(findHeaderRow, axis=1).dropna()\n",
    "        if len(headerConfig)>0:\n",
    "            progColName = headerConfig.values[0][0]\n",
    "        if progColName != False:\n",
    "            headers = []\n",
    "            buys = t.copy()\n",
    "            buys = buys.dropna(how='all')\n",
    "            buys = buys.iloc[headerConfig.values[0][1]:]\n",
    "            buys = buys.reset_index(drop=True)\n",
    "            #print(len(buys))\n",
    "            buys.apply(getDays, axis=1)\n",
    "            days = buys.iloc[headers]\n",
    "            days = days.replace('', np.nan)\n",
    "            days = days.dropna(axis='columns')\n",
    "            days.columns = days.iloc[0]\n",
    "            days = days[1:]\n",
    "            days = days.reset_index()\n",
    "            days['index'] = days['index'] + lastIndex\n",
    "            lastIndex = t.iloc[len(t)-1].name+lastIndex+1\n",
    "            ads = ads.append(days)\n",
    "    ## Add in Program Names\n",
    "    ads['Program'] = ads['index'].apply(mergeProgs)\n",
    "    ads = ads.drop(columns=['index'], axis=1)\n",
    "    #ads.apply(expandDays, axis=1)\n",
    "    '''\n",
    "    print('SHOWS')\n",
    "    print(shows)\n",
    "    print('ADS')\n",
    "    print(ads[['index', 'Weekdays']])\n",
    "    print(len(adtimes))\n",
    "    '''\n",
    "    ## Expand each ad buy listing to individual spots\n",
    "    return ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Committee</th>\n",
       "      <th>Station</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Rate, Committee, Station, Program]\n",
       "Index: []"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adtimes = adtimes.append({\n",
    "                                    'Date': (adStartDate + timedelta(days=i)),  \n",
    "                                    'Rate': x['Rate'],\n",
    "                                    'Committee': committee,\n",
    "                                    'Station': station,\n",
    "                                    'Program': x['Program']\n",
    "                                   }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCyclePDFs(cyc, basepath):\n",
    "    fulladlist = pd.DataFrame(columns=['Date', 'Rate', 'Committee', 'Station', 'Program'])\n",
    "    pdfResults = pd.DataFrame(columns=['Path', 'Result'])\n",
    "    def digToNextLevel(folderpath, name):\n",
    "        nonlocal pdfResults\n",
    "        nonlocal fulladlist\n",
    "        adtimes = [] # Final add array\n",
    "        stationads = pd.DataFrame(columns=['StartDate', 'EndDate', 'Weekdays',\n",
    "                                           'Spots/Week', 'Rate', 'Rating'])\n",
    "        def expandDays(x):\n",
    "            adStartDate = datetime.strptime(x['StartDate'], '%m/%d/%y')\n",
    "            for i, day in enumerate(x['Weekdays']):\n",
    "                if(day!='-'):\n",
    "                    if(day.isdigit()):\n",
    "                        for j in range(0, int(day)):\n",
    "                            adtimes.append({\n",
    "                                        'Date': (adStartDate + timedelta(days=i)),  \n",
    "                                        'Rate': x['Rate'],\n",
    "                                        'Committee': name,\n",
    "                                        'Station': station,\n",
    "                                        'Program': x['Program']\n",
    "                                       })\n",
    "                    else: ## CODE FOR MTW NOTATION\n",
    "                        adtimes.append({\n",
    "                                        'Date': (adStartDate + timedelta(days=i)),  \n",
    "                                        'Rate': x['Rate'],\n",
    "                                        'Committee': name,\n",
    "                                        'Station': station,\n",
    "                                        'Program': x['Program']\n",
    "                                       })\n",
    "        for item in list(os.scandir(folderpath)):\n",
    "            if (item.is_file()):\n",
    "                if (item.path.split('.')[1] == \"pdf\"):\n",
    "                    result = subprocess.run(['pdftotext', item.path, '-'], \n",
    "                                            stdout=subprocess.PIPE).stdout.decode()\n",
    "                    if (\"INVOICE\" not in result.split('\\n')[0:30]): ## Check if file is a contract/order.\n",
    "                        if((len(result.split('\\n')[0:30])> 5)):\n",
    "                            pdfTable = convertPDFToTable(item.path)\n",
    "                            try: \n",
    "                                ads = processTables(pdfTable, name, station)\n",
    "                                stationads = stationads.append(ads, ignore_index=True)\n",
    "                                print(len(stationads))\n",
    "                                pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                                                'Result': 'Success'}, ignore_index=True)\n",
    "                            except:\n",
    "                                 pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                                    'Result': 'Scraping Error'}, ignore_index=True)\n",
    "                        else:\n",
    "                            pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                               'Result': 'File not OCRd'}, ignore_index=True)\n",
    "                    else:\n",
    "                        pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                               'Result': 'Not an order file.'}, ignore_index=True)\n",
    "            else:\n",
    "                digToNextLevel(item.path, item.name)\n",
    "        if len(stationads)>0:\n",
    "            stationads = stationads.drop_duplicates()\n",
    "            stationads.apply(expandDays, axis=1)\n",
    "            fulladlist = fulladlist.append(pd.DataFrame(adtimes), ignore_index=True)\n",
    "    for station in list(os.scandir(basepath)):\n",
    "        station = station.name\n",
    "        cyclepath = basepath+station+'/Political Files/'+cyc+'/'\n",
    "        digToNextLevel(cyclepath, cyc)\n",
    "    fulladlist['Cycle'] = cyc\n",
    "\n",
    "    return {'ads': fulladlist, 'pdfs': pdfResults}\n",
    "results = parseCyclePDFs('2018', '/media/andrew/F08C9B848C9B444E/analysis/tv/buys/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['pdftotext', '/home/andrew/Documents/PredictiveModeling/TV/Invoice.pdf', '-'], \n",
    "                        stdout=subprocess.PIPE).stdout.decode()\n",
    "print(\"ORDER\" in result.split('\\n')[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62393"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['ads'].to_csv(index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
