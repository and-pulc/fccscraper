{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfminer as pm\n",
    "import math\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta  \n",
    "import warnings\n",
    "import os\n",
    "import subprocess\n",
    "import ocrmypdf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(p1t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in all table regions\n",
    "def convertPDFToTable(filepath):\n",
    "    table_cols = [['35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550'], \n",
    "                  ['44,']]\n",
    "    curColSetting = 0\n",
    "    p1t = camelot.read_pdf(filepath, \n",
    "                         strip_text=' .\\n', flavor='stream', pages=\"1-end\",\n",
    "                         #table_regions=['0,700,600,0'],\n",
    "                          columns=table_cols[curColSetting], \n",
    "                           edge_tol=75)\n",
    "    pdf = []\n",
    "    for t in p1t:\n",
    "        pdf.append(t.df)\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTables(tables, committee, station):\n",
    "    progColre=False\n",
    "    ## Create the ad day/times df.\n",
    "    ads = pd.DataFrame(columns=['StartDate', 'EndDate', 'Weekdays', 'Spots/Week', 'Rate', 'Rating', 'index'])\n",
    "    ## Create the shows DF.\n",
    "    shows = pd.DataFrame(columns=['index', 'Title'])\n",
    "    secondlines = pd.DataFrame(columns=['index', 'Title'])\n",
    "    ## Add second line of inventory code\n",
    "    def mergeSLines(row):\n",
    "        if row.name+1 < len(shows):\n",
    "            nextRow = shows.iloc[row.name+1]\n",
    "            sline = secondlines[(row['index'] < secondlines['index']) & (nextRow['index']>secondlines['index'])]\n",
    "        else: \n",
    "            sline = secondlines[(row['index'] < secondlines['index'])]\n",
    "        if(len(sline)>0):\n",
    "            if(row['Title'] != sline['Title'].values[0]):\n",
    "                row['Title'] = row['Title'] + sline['Title'].values[0]\n",
    "        else:\n",
    "            print('Second line merge error at ad: ', row.name)\n",
    "        return row\n",
    "    \n",
    "    def getSecondLines(df):\n",
    "        returnVal = pd.DataFrame(columns=['index', 'Title'])\n",
    "        #Get show lines\n",
    "        progs = df[(df['Amount'] != '') & (df['Ch'] != '')]\n",
    "        progs = progs.iloc[1:] # Remove residual header row.\n",
    "        slines = list(map(lambda x: x+1, progs.index.values))\n",
    "        if not (slines[-1] < len(df)): ## In case the second show line is on the next page.\n",
    "            print('Program second line on next page.')\n",
    "            slines = slines[:-1]\n",
    "        slines = df.iloc[slines]\n",
    "        slines = slines.replace('', np.nan, regex=True)\n",
    "        slines = slines[slines.isnull().sum(axis=1) == len(slines.columns)-1]\n",
    "        for index, row in slines.iterrows():\n",
    "            nulls = pd.isnull(row)\n",
    "            nulls = nulls[nulls!=True]\n",
    "            returnVal = returnVal.append({'index': index, 'Title': row[nulls.index[0]]}, ignore_index=True)\n",
    "        returnVal['index'] = returnVal['index'] + lastIndex\n",
    "        return returnVal\n",
    "    def addNameIfDiff(p):\n",
    "        for val in nlines.iloc[p.name]:\n",
    "            if(p[progColName] != val) & (val.isna() != True):\n",
    "                p[progColName] = p[progColName] + val\n",
    "        return p\n",
    "    ## Merge program names into ad days.\n",
    "    def mergeProgs(i):\n",
    "        p = shows[shows['index']<=i]\n",
    "        p = p.iloc[len(p)-1]\n",
    "        return p['Title']\n",
    "    ## Create individual records for each ad spot.  \n",
    "    ## Filter out day times rows.                \n",
    "    def getDays(row):\n",
    "        #print(row)\n",
    "        nextRow = 1\n",
    "        dayCols = ['StartDate', 'EndDate', 'Weekdays', 'Spots/Week', 'Rate']\n",
    "        for val in row:\n",
    "            try:\n",
    "                ind = dayCols.index(val)\n",
    "                dayCols.remove(val)\n",
    "            except:\n",
    "                pass\n",
    "        if(len(dayCols) == 0):\n",
    "            if(len(headers)==0):\n",
    "                headers.append(row.name)\n",
    "            while (nextRow!=-1):\n",
    "                dayColFound=False\n",
    "                if((row.name+nextRow) != len(buys)):\n",
    "                    for k in buys.loc[(row.name+nextRow), :]:\n",
    "                        if k == 'Week:':\n",
    "                            headers.append((row.name+nextRow))\n",
    "                            nextRow=nextRow+1\n",
    "                            dayColFound=True\n",
    "                    if dayColFound!=True:\n",
    "                        nextRow=-1\n",
    "                else:\n",
    "                    nextRow=-1\n",
    "    def findHeaderRow(row):\n",
    "        headers =  { 'Type1': ['StartDateEndDateDescription'],\n",
    "                     'Type2': ['Amount', 'Start', 'InventoryCode', 'Rate', 'Spots'] }\n",
    "        for htype in headers:\n",
    "            for val in row:\n",
    "                try:\n",
    "                    ind = headers[htype].index(val)\n",
    "                    headers[htype].remove(val)\n",
    "                except:\n",
    "                    pass\n",
    "        if(len(headers['Type1']) == 0):\n",
    "            return ['Description', row.name]\n",
    "        else:\n",
    "            if(len(headers['Type2']) == 0):\n",
    "                return ['InventoryCode', row.name]\n",
    "    def fixHeaders(row):\n",
    "        fixCol = -1\n",
    "        for k in row.keys():\n",
    "            if row[k] == 'StartDateEndDateDescription':\n",
    "                fixCol = k\n",
    "        if fixCol != -1:\n",
    "            if(fixCol == 3):\n",
    "                row[(fixCol-2)] = 'Ch'\n",
    "                row[(fixCol-1)] = 'Start'\n",
    "                row[(fixCol)] = 'End'\n",
    "                row[(fixCol+1)] = 'Description'\n",
    "                row[(fixCol+2)] = 'Desc2'\n",
    "            if(fixCol == 2):\n",
    "                row[(fixCol)] = 'Start'\n",
    "                row[(fixCol+1)] = 'End'\n",
    "                row[(fixCol+2)] = 'Description'\n",
    "        return row\n",
    "    ## Filter out program names.\n",
    "    lastIndex = 0\n",
    "    for t in tables:\n",
    "        progColName=False\n",
    "        headerConfig = t.apply(findHeaderRow, axis=1).dropna()\n",
    "        if len(headerConfig)>0:\n",
    "            progColName = headerConfig.values[0][0]\n",
    "        if progColName != False:\n",
    "            ## Figure out inventory code lines\n",
    "            progs = t.copy()\n",
    "            if progColName == 'Description':\n",
    "                progs = progs.apply(fixHeaders, axis=1)\n",
    "                progs.columns = progs.iloc[headerConfig.values[0][1]]\n",
    "            else:\n",
    "                progs.columns = progs.iloc[headerConfig.values[0][1]]\n",
    "            progs = progs.iloc[headerConfig.values[0][1]:]\n",
    "            progs = progs.reset_index(drop=True)\n",
    "            \n",
    "            ## Some WideOrbit reports have two line program names, this gets the second lines.\n",
    "            if progColName == 'InventoryCode':\n",
    "                slines = getSecondLines(progs)\n",
    "                secondlines = secondlines.append(slines)\n",
    "            ## Get the program name rows\n",
    "            progs = progs[(progs['Amount'] != '') & (progs['Ch'] != '')] \n",
    "            progs = progs.iloc[1:] # Remove residual header row.\n",
    "            if progColName == 'Description':\n",
    "                progs['Description'] = progs['Description'] + progs['Desc2']\n",
    "            progs = progs.reset_index()\n",
    "            ## Make index run continously accross pages.\n",
    "            progs['index'] = progs['index'] + lastIndex\n",
    "            lastIndex = t.iloc[len(t)-1].name+lastIndex+1\n",
    "            ## Remove duplicate columns and append to the master list.\n",
    "            progs = progs.loc[:,~progs.columns.duplicated()]\n",
    "            progs = progs.rename(columns={progColName:'Title'})\n",
    "            progs = progs[['index', 'Title']]\n",
    "            shows = shows.append(progs)\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"False\")\n",
    "    ## Merge in the second lines to complete the program names.\n",
    "    if progColName == 'InventoryCode':\n",
    "        shows = shows.reset_index(drop=True)\n",
    "        shows = shows.apply(mergeSLines, axis=1)\n",
    "    ## Seperate out the days and times each ad will be on.\n",
    "    lastIndex = 0\n",
    "    for t in tables:\n",
    "        progColName=False\n",
    "        headerConfig = t.apply(findHeaderRow, axis=1).dropna()\n",
    "        if len(headerConfig)>0:\n",
    "            progColName = headerConfig.values[0][0]\n",
    "        if progColName != False:\n",
    "            headers = []\n",
    "            buys = t.copy()\n",
    "            buys = buys.dropna(how='all')\n",
    "            buys = buys.iloc[headerConfig.values[0][1]:]\n",
    "            buys = buys.reset_index(drop=True)\n",
    "            #print(len(buys))\n",
    "            buys.apply(getDays, axis=1)\n",
    "            days = buys.iloc[headers]\n",
    "            days = days.replace('', np.nan)\n",
    "            days = days.dropna(axis='columns')\n",
    "            days.columns = days.iloc[0]\n",
    "            days = days[1:]\n",
    "            days = days.reset_index()\n",
    "            days['index'] = days['index'] + lastIndex\n",
    "            lastIndex = t.iloc[len(t)-1].name+lastIndex+1\n",
    "            ads = ads.append(days)\n",
    "    ## Add in Program Names\n",
    "    ads['Program'] = ads['index'].apply(mergeProgs)\n",
    "    ads = ads.drop(columns=['index'], axis=1)\n",
    "    '''\n",
    "    print('SHOWS')\n",
    "    print(shows)\n",
    "    print('ADS')\n",
    "    print(ads[['index', 'Weekdays']])\n",
    "    print(len(adtimes))\n",
    "    '''\n",
    "    ## Expand each ad buy listing to individual spots\n",
    "    return ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCyclePDFs(cyc, basepath, test):\n",
    "    fulladlist = pd.DataFrame(columns=['Date', 'Rate', 'Committee', 'Station', 'Program'])\n",
    "    pdfResults = pd.DataFrame(columns=['Path', 'Result'])\n",
    "    def digToNextLevel(folderpath, name):\n",
    "        nonlocal pdfResults\n",
    "        nonlocal fulladlist\n",
    "        adtimes = [] # Final add array\n",
    "        stationads = pd.DataFrame(columns=['StartDate', 'EndDate', 'Weekdays',\n",
    "                                           'Spots/Week', 'Rate', 'Rating'])\n",
    "        def expandDays(x):\n",
    "            adStartDate = datetime.strptime(x['StartDate'], '%m/%d/%y')\n",
    "            for i, day in enumerate(x['Weekdays']):\n",
    "                if(day!='-'):\n",
    "                    if(day.isdigit()):\n",
    "                        for j in range(0, int(day)):\n",
    "                            adtimes.append({\n",
    "                                        'Date': (adStartDate + timedelta(days=i)),  \n",
    "                                        'Rate': x['Rate'],\n",
    "                                        'Committee': name,\n",
    "                                        'Station': station,\n",
    "                                        'Program': x['Program']\n",
    "                                       })\n",
    "                    else: ## CODE FOR MTW NOTATION\n",
    "                        adtimes.append({\n",
    "                                        'Date': (adStartDate + timedelta(days=i)),  \n",
    "                                        'Rate': x['Rate'],\n",
    "                                        'Committee': name,\n",
    "                                        'Station': station,\n",
    "                                        'Program': x['Program']\n",
    "                                       })\n",
    "        def determinePdfFormat(text):\n",
    "            textAr = text.split('\\n')\n",
    "            \n",
    "        def processPDF(item, station, name):\n",
    "            nonlocal pdfResults\n",
    "            nonlocal fulladlist\n",
    "            nonlocal stationads\n",
    "            result = subprocess.run(['pdftotext', item.path, '-'], \n",
    "                                        stdout=subprocess.PIPE).stdout.decode()\n",
    "            determinePdfFormat(result)\n",
    "            if (\"INVOICE\" not in result.split('\\n')[0:30]) & (\"ORDER\" in result.split('\\n')[0:30]): ## Check if file is a contract/order. THIS NEEDS TO BE SUBSTANTIALLY MORE DETAILED ONCE OCR STARTS\n",
    "                if((len(result.split('\\n')[0:30])> 5)):\n",
    "                    print(item.path)\n",
    "                    pdfTable = convertPDFToTable(item.path)\n",
    "                    try: \n",
    "                        ads = processTables(pdfTable, name, station)\n",
    "                        if len(ads) > 0:\n",
    "                            stationads = stationads.append(ads, ignore_index=True)\n",
    "                            pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                                            'Result': 'Success'}, ignore_index=True)\n",
    "                        else:\n",
    "                            pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                            'Result': 'Scraping Error'}, ignore_index=True)\n",
    "                    except:\n",
    "                         pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                            'Result': 'Scraping Error'}, ignore_index=True)\n",
    "                else:\n",
    "                    print('OCR')\n",
    "                    ocrmypdf.ocr(item.path, item.path, deskew=True, rotate_pages=True)\n",
    "                    processPDF(item, station, name)\n",
    "            else:\n",
    "                print('test')\n",
    "                pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                       'Result': 'Not an order file.'}, ignore_index=True)\n",
    "        for item in list(os.scandir(folderpath)):\n",
    "            if (item.is_file()):\n",
    "                processPDF(item, station, name)\n",
    "            else:\n",
    "                digToNextLevel(item.path, item.name)\n",
    "        if len(stationads)>0:\n",
    "            stationads = stationads.drop_duplicates()\n",
    "            stationads.apply(expandDays, axis=1)\n",
    "            fulladlist = fulladlist.append(pd.DataFrame(adtimes), ignore_index=True)\n",
    "    if test:\n",
    "        station = 'test'\n",
    "        digToNextLevel(basepath, cyc)\n",
    "    else:\n",
    "        for station in list(os.scandir(basepath)):\n",
    "            station = station.name\n",
    "            cyclepath = basepath+station+'/Political Files/'+cyc+'/'\n",
    "            digToNextLevel(cyclepath, cyc)\n",
    "        fulladlist['Cycle'] = cyc\n",
    "\n",
    "    return {'ads': fulladlist, 'pdfs': pdfResults}\n",
    "results = parseCyclePDFs('2018', '/media/andrew/F08C9B848C9B444E/analysis/tv/tuctest/', test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['pdfs']['Path'] = results['pdfs']['Path'].str[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Scraping Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>/media/andrew/F08C9B848C9B444E/analysis/tv/tuc...</td>\n",
       "      <td>Not an order file.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Path              Result\n",
       "0   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...      Scraping Error\n",
       "1   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "2   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "3   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "4   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "5   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "6   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "7   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "8   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "9   /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "10  /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "11  /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "12  /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "13  /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "14  /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file.\n",
       "15  /media/andrew/F08C9B848C9B444E/analysis/tv/tuc...  Not an order file."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['pdfs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Committee</th>\n",
       "      <th>Station</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Rate, Committee, Station, Program]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['ads'][results['ads']['Program'].str.contains('Prime')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62393"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocrmypdf.ocr('input.pdf', 'output.pdf', deskew=True, rotate_pages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "9\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Generating keys for predicting what form a PDF is in.\n",
    "keys = {}\n",
    "for ftype in list(os.scandir('/media/andrew/F08C9B848C9B444E/analysis/tv/orderscoring/')):\n",
    "    o = list(os.scandir('/media/andrew/F08C9B848C9B444E/analysis/tv/orderscoring/'+ftype.name+'/'))\n",
    "    op = []\n",
    "    # Convert all pdfs to text, string process them and turn them into an array of strings\n",
    "    for f in o:\n",
    "        res = subprocess.run(['pdftotext', f.path, '-'], \n",
    "                                            stdout=subprocess.PIPE).stdout.decode()\n",
    "        res = res.split('\\n')\n",
    "        res = [x.replace(' ', '') for x in res ]\n",
    "        res = [x.replace(':', '') for x in res ]\n",
    "        res = [x.replace('.', '') for x in res ]\n",
    "        res = list(filter(lambda a: a != '', res))\n",
    "        res = res[0:300]\n",
    "        res = list(set(res))\n",
    "        #print(res[0:100])\n",
    "        if len(res)>1:\n",
    "            op.append(res)\n",
    "        else:\n",
    "            ocrmypdf.ocr(f.path, f.path, deskew=True, rotate_pages=True)\n",
    "    curSet = []\n",
    "    # Filter so only keys that exist in all files of the given report format remain.\n",
    "    print(len(op))\n",
    "    for l in op:\n",
    "        if len(curSet)==0:\n",
    "            curSet=l\n",
    "        else:\n",
    "            curSet = [x for x in curSet if x in l]\n",
    "    keys[ftype.name] = curSet\n",
    "# Filter out keys that are non-unique to that report type.\n",
    "for k in keys:\n",
    "    types = ['contracts', 'invoices', 'orders']\n",
    "    types = [x for x in types if x != k]\n",
    "    for t in types:\n",
    "        keys[k] = [x for x in keys[k] if x not in keys[t]]\n",
    "    # Get rid of nonspecific keys\n",
    "    keys[k] = list(filter(lambda a: (len(a)>4) & (len(a)<23) , keys[k]))\n",
    "keys = [[(k, vv) for vv in v] for k, v in keys.items()]\n",
    "keys2 = []\n",
    "for k in keys:\n",
    "    for v in k:\n",
    "        keys2.append(v)\n",
    "keys = pd.DataFrame(keys2, columns=['pdftype', 'keyword'])\n",
    "keys.to_csv('filetypekeywords.csv', index=False)\n",
    "#print(curSet)\n",
    "#print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classifyReportFormat():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdftype</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>contracts</td>\n",
       "      <td>Contract/Revision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>contracts</td>\n",
       "      <td>Start/End</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>contracts</td>\n",
       "      <td>Spots/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>contracts</td>\n",
       "      <td>Cash/Trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>contracts</td>\n",
       "      <td>LengthWeek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pdftype            keyword\n",
       "0  contracts  Contract/Revision\n",
       "1  contracts          Start/End\n",
       "2  contracts             Spots/\n",
       "3  contracts         Cash/Trade\n",
       "4  contracts         LengthWeek"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "keys3.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
