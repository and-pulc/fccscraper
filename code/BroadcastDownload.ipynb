{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os, sys\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get TV Stations by DMA\n",
    "#dma = \"PHOENIX (PRESCOTT)\"\n",
    "dma = \"TUCSON (SIERRA VISTA)\"\n",
    "url = \"https://publicfiles.fcc.gov/api/service/facility/search/\"+dma.split()[0]+\".json\"\n",
    "r = requests.get(url).json()\n",
    "tv = pd.DataFrame(r['results']['globalSearchResults']['tvFacilityList'])\n",
    "tv = tv[tv.nielsenDma==dma]\n",
    "tv = tv[['callSign','communityState','networkAfil','nielsenDma','virtualChannel','id']]\n",
    "tv['medium'] = \"broadcast\"\n",
    "tv = tv.rename(columns={'callSign':'sign', 'communityState':'state', 'networkAfil': 'network',\n",
    "                       'nielsenDma':'dma', 'virtualChannel':'channel'})\n",
    "tv.to_csv(('stations'+dma+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmafolder created\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KGUN-TV exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KHRR exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KMSB exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KOLD-TV exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KTTU exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KUAS-TV exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KUAT-TV exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KVOA exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KFTU-DT exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KUVE-DT exists\n",
      "\n",
      "\n",
      "/media/andrew/F08C9B848C9B444E/analysis/tv/buys/TUCSON (SIERRA VISTA)/KWBA-TV exists\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create folders for each station.\n",
    "def createStationFolders(s):\n",
    "    path = \"/media/andrew/F08C9B848C9B444E/analysis/tv/buys/\"+s['dma']+\"/\"+s['sign']\n",
    "    #path = \"/home/andrew/Documents/PredictiveModeling/TV/stations/\"+s\n",
    "    try: \n",
    "        os.mkdir(path)\n",
    "    except FileExistsError:\n",
    "        print(path+\" exists\")\n",
    "    try:\n",
    "        os.mkdir(path+\"/Political Files\")\n",
    "    except FileExistsError:\n",
    "        print('')\n",
    "    try:\n",
    "        os.mkdir(path+\"/Political Files/2018\")\n",
    "    except FileExistsError:\n",
    "        print('')\n",
    "try: # Create DMA folder\n",
    "    os.mkdir('/media/andrew/F08C9B848C9B444E/analysis/tv/buys/'+tv[0:1]['dma'].values[0])\n",
    "except FileExistsError:\n",
    "    print('dmafolder created')\n",
    "tv.apply(createStationFolders, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the head political Folder\n",
    "cycle = '18'\n",
    "def getFileFolder(iD):\n",
    "    url = 'https://publicfiles.fcc.gov/api/manager/folder/path.json'\n",
    "    folder = 'Political Files/20'+cycle\n",
    "    r = requests.get(url, params={\"folderPath\":folder, \"entityId\": iD, 'sourceService':'tv'}).json()\n",
    "    if r['statusCode'] == 200:\n",
    "        return r['folder'][0]['entity_folder_id']\n",
    "    else:\n",
    "        return None\n",
    "tv[(cycle+'PoliticalFolder')] = tv['id'].apply(getFileFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all directory folders\n",
    "cycle = '18'\n",
    "import time\n",
    "def createBuyFolders(s):\n",
    "    print(s)\n",
    "    if s[(cycle+'PoliticalFolder')] != None:\n",
    "        url = \"https://publicfiles.fcc.gov/api/manager/folder/id/\"+s[(cycle+'PoliticalFolder')]+\".json\"\n",
    "        digToNextLevel(s[(cycle+'PoliticalFolder')], s['id'], s['sign'], s['dma'], False)\n",
    "tv[[(cycle+'PoliticalFolder'),'id','sign', 'dma']].apply(createBuyFolders, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turn the pac folders into a PAC csv for processing.\n",
    "juris = ['Federal', 'Local', 'Non-Candidate Issue Ads', 'State']\n",
    "fedrace = ['President', 'US Senate', 'US House']\n",
    "pacs = []\n",
    "def getAllPacs(s):\n",
    "    basepath = \"/home/andrew/Documents/PredictiveModeling/TV/stations/\"+s['sign']+'/Political Files/'+cycle+'/'\n",
    "    try:\n",
    "        os.scandir(basepath)\n",
    "        for j in juris:\n",
    "            path = basepath + j\n",
    "            if j == 'Federal':\n",
    "                for r in fedrace:\n",
    "                    fedpath = path+'/'+r\n",
    "                    if r == 'US House': # Sometimes House folders have districts\n",
    "                        dist = []\n",
    "                        fcontents = list(os.scandir(fedpath)) \n",
    "                        if len(fcontents) >0:\n",
    "                            for f in fcontents:## US House\n",
    "                                if f.is_dir():\n",
    "                                    distpath = fedpath+'/'+f.name\n",
    "                                    fileFound = False\n",
    "                                    for p in list(os.scandir(distpath)): ## Subfolder, is it district or pac?\n",
    "                                        if p.is_dir() == True:\n",
    "                                            pacs.append({\"Name\": p.name, \"Jurisdiction\": j, \"Race\": None, \"Station\":s['sign'], \n",
    "                                                 \"Path\": f.path, 'District': f.name, \"Cycle\": cycle})\n",
    "                                        else:\n",
    "                                            fileFound=True\n",
    "                                    if (fileFound) or len(list(os.scandir(distpath))) == 0:\n",
    "                                        pacs.append({\"Name\": f.name, \"Jurisdiction\": j, \"Race\": None, \"Station\":s['sign'], \n",
    "                                                 \"Path\": f.path, 'District': None, \"Cycle\": cycle})   \n",
    "                        else:\n",
    "                            for f in fcontents:\n",
    "                                pacs.append({\"Name\": p.name, \"Jurisdiction\": j, \"Race\": None, \"Station\":s['sign'], \"Path\": p.path, 'District': None, \"Cycle\": cycle})\n",
    "                    else:\n",
    "                        for p in list(os.scandir(fedpath)):\n",
    "                            if p.is_dir():\n",
    "                                pacs.append({\"Name\": p.name, \"Jurisdiction\": j, \"Race\": None, \"Station\":s['sign'], \"Path\": p.path, 'District': None, \"Cycle\": cycle})\n",
    "            if j == 'State':\n",
    "                fcontents = list(os.scandir(path))\n",
    "                if len(fcontents)>0:\n",
    "                    for r in fcontents: # Loop through folders in the State folder.\n",
    "                        # Folder two contents,\n",
    "                        fileFound = False\n",
    "                        f2path = path+'/'+r.name\n",
    "                        f2contents = list(os.scandir(f2path))\n",
    "                        for f in f2contents:\n",
    "                            if (f.is_dir()) & (\"Invoices\" in f.name == False):\n",
    "                                pacs.append({\"Name\": f.name, \"Jurisdiction\": j, \"Race\": r.name, \n",
    "                                             \"Station\":s['sign'], \"Path\": f.path,'District': None,\n",
    "                                             \"Cycle\": cycle})\n",
    "                            else:\n",
    "                                fileFound = True\n",
    "                        if (fileFound) or (len(f2contents)==0):\n",
    "                            pacs.append({\"Name\": r.name, \"Jurisdiction\": j, \"Race\": None, \"Station\":s['sign'], \n",
    "                                        \"Path\": r.path, 'District': None, \"Cycle\": cycle})\n",
    "            if (j != 'Federal') & (j != 'State'):\n",
    "                for p in list(os.scandir(path)):\n",
    "                    if p.is_dir():\n",
    "                        pacs.append({\"Name\": p.name, \"Jurisdiction\": j, \"Race\": None, \"Station\":s['sign'], \"Path\": p.path, 'District': None, \"Cycle\": cycle})\n",
    "    except:\n",
    "        return\n",
    "\n",
    "cycles = ['2018'] #,'2016','2014']\n",
    "\n",
    "for c in cycles:\n",
    "    cycle = c\n",
    "    tv.apply(getAllPacs, axis=1)\n",
    "pacs = pd.DataFrame(pacs)\n",
    "pacs.to_csv('pacs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KVOA\n",
      "KFTU-DT\n",
      "KUVE-DT\n",
      "KWBA-TV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download all files in containing folders.\n",
    "dlurl = 'https://publicfiles.fcc.gov/api/manager/download/' # folder/fileid.pdf\n",
    "folderurl = 'https://publicfiles.fcc.gov/api/manager/folder/id/' # id.json\n",
    "def digToNextLevel(fId, tvId, sCs, dma, dlFiles):\n",
    "    #path = \"/home/andrew/Documents/PredictiveModeling/TV/stations/\"\n",
    "    dlurl = 'https://publicfiles.fcc.gov/api/manager/download/' # folder/fileid.pdf\n",
    "    path = \"/media/andrew/F08C9B848C9B444E/analysis/tv/buys/\"+dma+'/'\n",
    "    url = \"https://publicfiles.fcc.gov/api/manager/folder/id/\"+fId+\".json\"\n",
    "    r = requests.get(url,params={'entityId':tvId}).json()\n",
    "    if r['statusCode'] == 200:\n",
    "        if dlFiles:\n",
    "            if (len(r['folder']['files'])>0):\n",
    "                for pdf in r['folder']['files']:\n",
    "                    if (pdf['file_extension'] == 'pdf') & ('com' in pdf['file_status']):\n",
    "                        #print(pdf)\n",
    "                        dlr = requests.get(dlurl+pdf['folder_id']+\"/\"+pdf['file_manager_id']+'.pdf',params={'entityId':tvId}) # DL Request\n",
    "                        #print((path+sCs+'/'+r['folder']['folder_path']+'/'+pdf['file_name']+'.pdf'))\n",
    "                        #print(dlr)\n",
    "                        with open(path+sCs+'/'+r['folder']['folder_path']+'/'+pdf['file_name']+'.pdf', 'wb') as dlf: # DL File\n",
    "                            dlf.write(dlr.content)\n",
    "            for sf in r['folder']['subfolders']:\n",
    "                digToNextLevel(sf[\"entity_folder_id\"], sf[\"entity_id\"], sCs, dma, dlFiles)\n",
    "        else:\n",
    "            try:\n",
    "                os.mkdir(path+sCs+\"/\"+r['folder']['folder_path'])\n",
    "            except FileExistsError:\n",
    "                print(path+sCs+\"/\"+r['folder']['folder_path']+\" exists\")\n",
    "            except FileNotFoundError:\n",
    "                folders = r['folder']['folder_path'].split('/')\n",
    "                curPath = \"\"\n",
    "                for folder in folders:\n",
    "                    try:\n",
    "                        curPath = curPath+\"/\"+folder\n",
    "                        os.mkdir(path+sCs+\"/\"+curPath)\n",
    "                    except FileExistsError:\n",
    "                        print('folder exists')\n",
    "                print(path+sCs+\"/\"+r['folder']['folder_path']+\" exists\")\n",
    "            if len(r['folder']['subfolders']) > 0:\n",
    "                for sf in r['folder']['subfolders']:\n",
    "                    digToNextLevel(sf[\"entity_folder_id\"], sf[\"entity_id\"], sCs, dma, dlFiles)\n",
    "    else:\n",
    "        print(r['statusMessage'])\n",
    "        time.sleep(10)\n",
    "        digToNextLevel(fId, tvId, sCs, dma, dlFiles)\n",
    "def downloadBuyPDFs(s): # station\n",
    "    print(s['sign'])\n",
    "    digToNextLevel(s[(cycle+'PoliticalFolder')], s['id'], s['sign'], s['dma'], True)\n",
    "tv[7:].apply(downloadBuyPDFs, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
