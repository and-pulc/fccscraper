{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfminer as pm\n",
    "import math\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta  \n",
    "import warnings\n",
    "import os\n",
    "import subprocess\n",
    "import ocrmypdf\n",
    "import sys\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(p1t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in all table regions\n",
    "def convertPDFToTable(filepath):\n",
    "    table_cols = [['35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550',\n",
    "                  '35,52,97,136,210,256,308,360,390,422,456,469,490,513,550'], \n",
    "                  ['44,']]\n",
    "    curColSetting = 0\n",
    "    p1t = camelot.read_pdf(filepath, \n",
    "                         strip_text=' .\\n', flavor='stream', pages=\"1-end\",\n",
    "                         #table_regions=['0,700,600,0'],\n",
    "                          columns=table_cols[curColSetting], \n",
    "                           edge_tol=100)\n",
    "    pdf = []\n",
    "    for t in p1t:\n",
    "        pdf.append(t.df)\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOrder(tables, committee, station):\n",
    "    progColre=False\n",
    "    ## Create the ad day/times df.\n",
    "    ads = pd.DataFrame(columns=['StartDate', 'EndDate', 'Weekdays', 'Spots/Week', 'Rate', 'Rating', 'index'])\n",
    "    ## Create the shows DF.\n",
    "    shows = pd.DataFrame(columns=['index', 'Title'])\n",
    "    secondlines = pd.DataFrame(columns=['index', 'Title'])\n",
    "    ## Add second line of inventory code\n",
    "    def mergeSLines(row):\n",
    "        if row.name+1 < len(shows):\n",
    "            nextRow = shows.iloc[row.name+1]\n",
    "            sline = secondlines[(row['index'] < secondlines['index']) & (nextRow['index']>secondlines['index'])]\n",
    "        else: \n",
    "            sline = secondlines[(row['index'] < secondlines['index'])]\n",
    "        if(len(sline)>0):\n",
    "            if(row['Title'] != sline['Title'].values[0]):\n",
    "                row['Title'] = row['Title'] + sline['Title'].values[0]\n",
    "        else:\n",
    "            print('Second line merge error at ad: ', row.name)\n",
    "        return row\n",
    "    \n",
    "    def getSecondLines(df):\n",
    "        returnVal = pd.DataFrame(columns=['index', 'Title'])\n",
    "        #Get show lines\n",
    "        progs = df[(df['Amount'] != '') & (df['Ch'] != '')]\n",
    "        progs = progs.iloc[1:] # Remove residual header row.\n",
    "        slines = list(map(lambda x: x+1, progs.index.values))\n",
    "        if not (slines[-1] < len(df)): ## In case the second show line is on the next page.\n",
    "            print('Program second line on next page.')\n",
    "            slines = slines[:-1]\n",
    "        slines = df.iloc[slines]\n",
    "        slines = slines.replace('', np.nan, regex=True)\n",
    "        slines = slines[slines.isnull().sum(axis=1) >= len(slines.columns)-2]\n",
    "        for index, row in slines.iterrows():\n",
    "            nulls = pd.isnull(row)\n",
    "            nulls = nulls[nulls!=True]\n",
    "            returnVal = returnVal.append({'index': index, 'Title': row[nulls.index[0]]}, ignore_index=True)\n",
    "        returnVal['index'] = returnVal['index'] + lastIndex\n",
    "        return returnVal\n",
    "    def addNameIfDiff(p):\n",
    "        for val in nlines.iloc[p.name]:\n",
    "            if(p[progColName] != val) & (val.isna() != True):\n",
    "                p[progColName] = p[progColName] + val\n",
    "        return p\n",
    "    ## Merge program names into ad days.\n",
    "    def mergeProgs(i):\n",
    "        p = shows[shows['index']<=i]\n",
    "        if len(p)>0:\n",
    "            p = p.iloc[len(p)-1]\n",
    "            return p['Title']\n",
    "        else:\n",
    "            return \"\"\n",
    "    ## Create individual records for each ad spot.  \n",
    "    ## Filter out day times rows.                \n",
    "    def getDays(row):\n",
    "        #print(row)\n",
    "        nextRow = 1\n",
    "        dayCols = ['StartDate', 'EndDate', 'Weekdays', 'Spots/Week', 'Rate']\n",
    "        for val in row:\n",
    "            try:\n",
    "                ind = dayCols.index(val)\n",
    "                dayCols.remove(val)\n",
    "            except:\n",
    "                pass\n",
    "        if(len(dayCols) == 0):\n",
    "            if(len(headers)==0):\n",
    "                headers.append(buys.loc[(row.name), :])\n",
    "            while (nextRow!=-1):\n",
    "                dayColFound=False\n",
    "                if((row.name+nextRow) != len(buys)):\n",
    "                    potRow = buys.loc[(row.name+nextRow), :]\n",
    "                    valCount=0\n",
    "                    for k in potRow:\n",
    "                        if 'Week:' in k:\n",
    "                            if len(k.split(':'))>1:\n",
    "                                fixVal = k.split(':')[1]\n",
    "                                potRow[valCount+1] = fixVal\n",
    "                            nextRow=nextRow+1\n",
    "                            dayColFound=True\n",
    "                        valCount = valCount+1\n",
    "                    if dayColFound != True:\n",
    "                        nextRow=-1\n",
    "                    else:\n",
    "                        headers.append(potRow)\n",
    "                else:\n",
    "                    nextRow=-1\n",
    "    def findHeaderRow(row):\n",
    "        headers =  { 'Description': ['StartDateEndDateDescription'],\n",
    "                     'InventoryCode': ['Amount', 'Start', 'InventoryCode', 'Rate', 'Spots'] }\n",
    "        for htype in headers:\n",
    "            for val in row:\n",
    "                try:\n",
    "                    ind = headers[htype].index(val)\n",
    "                    headers[htype].remove(val)\n",
    "                except:\n",
    "                    pass\n",
    "        if(len(headers['Description']) == 0):\n",
    "            return ['Description', row.name]\n",
    "        else:\n",
    "            if(len(headers['InventoryCode']) == 0):\n",
    "                return ['InventoryCode', row.name]\n",
    "    def fixHeaders(row):\n",
    "        fixCol = -1\n",
    "        for k in row.keys():\n",
    "            if row[k] == 'StartDateEndDateDescription':\n",
    "                fixCol = k\n",
    "        if fixCol != -1:\n",
    "            if(fixCol == 3):\n",
    "                row[(fixCol-2)] = 'Ch'\n",
    "                row[(fixCol-1)] = 'Start'\n",
    "                row[(fixCol)] = 'End'\n",
    "                row[(fixCol+1)] = 'Description'\n",
    "                row[(fixCol+2)] = 'Desc2'\n",
    "            if(fixCol == 2):\n",
    "                row[(fixCol)] = 'Start'\n",
    "                row[(fixCol+1)] = 'End'\n",
    "                row[(fixCol+2)] = 'Description'\n",
    "        return row\n",
    "    ## Filter out program names.\n",
    "    lastIndex = 0\n",
    "    for t in tables:\n",
    "        progColName=False\n",
    "        headerConfig = t.apply(findHeaderRow, axis=1).dropna()\n",
    "        if len(headerConfig)>0:\n",
    "            progColName = headerConfig.values[0][0]\n",
    "        if progColName != False:\n",
    "            ## Figure out inventory code lines\n",
    "            progs = t.copy()\n",
    "            if progColName == 'Description':\n",
    "                progs = progs.apply(fixHeaders, axis=1)\n",
    "                progs.columns = progs.iloc[headerConfig.values[0][1]]\n",
    "            else:\n",
    "                progs.columns = progs.iloc[headerConfig.values[0][1]]\n",
    "            progs = progs.iloc[headerConfig.values[0][1]:]\n",
    "            progs = progs.reset_index(drop=True)\n",
    "            \n",
    "            ## Some WideOrbit reports have two line program names, this gets the second lines.\n",
    "            if progColName == 'InventoryCode':\n",
    "                slines = getSecondLines(progs)\n",
    "                secondlines = secondlines.append(slines)\n",
    "            ## Get the program name rows\n",
    "            progs = progs[(progs['Amount'] != '') & (progs['Ch'] != '')] \n",
    "            progs = progs.iloc[1:] # Remove residual header row.\n",
    "            if progColName == 'Description':\n",
    "                progs['Description'] = progs['Description'] + progs['Desc2']\n",
    "            progs = progs.reset_index()\n",
    "            ## Make index run continously accross pages.\n",
    "            progs['index'] = progs['index'] + lastIndex\n",
    "            lastIndex = t.iloc[len(t)-1].name+lastIndex+1\n",
    "            ## Remove duplicate columns and append to the master list.\n",
    "            progs = progs.loc[:,~progs.columns.duplicated()]\n",
    "            progs = progs.rename(columns={progColName:'Title'})\n",
    "            progs = progs[['index', 'Title']]\n",
    "            shows = shows.append(progs, sort=False)\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"False\")\n",
    "    ## Merge in the second lines to complete the program names.\n",
    "    if progColName == 'InventoryCode':\n",
    "        shows = shows.reset_index(drop=True)\n",
    "        shows = shows.apply(mergeSLines, axis=1)\n",
    "    ## Seperate out the days and times each ad will be on.\n",
    "    lastIndex = 0\n",
    "    for t in tables:\n",
    "        progColName=False\n",
    "        headerConfig = t.apply(findHeaderRow, axis=1).dropna()\n",
    "        if len(headerConfig)>0:\n",
    "            progColName = headerConfig.values[0][0]\n",
    "        if progColName != False:\n",
    "            headers = []\n",
    "            buys = t.copy()\n",
    "            buys = buys.dropna(how='all')\n",
    "            buys = buys.iloc[headerConfig.values[0][1]:]\n",
    "            buys = buys.reset_index(drop=True)\n",
    "            buys.apply(getDays, axis=1)\n",
    "            days = pd.DataFrame(headers)\n",
    "            days = days.replace('', np.nan)\n",
    "            days = days.dropna(axis='columns')\n",
    "            days.columns = days.iloc[0]\n",
    "            days = days[1:]\n",
    "            days = days.reset_index()\n",
    "            days['index'] = days['index'] + lastIndex\n",
    "            lastIndex = t.iloc[len(t)-1].name+lastIndex+1\n",
    "            ads = ads.append(days, sort=False)\n",
    "    ## Add in Program Names\n",
    "    ads['Program'] = ads['index'].apply(mergeProgs)\n",
    "    ads = ads.drop(columns=['index'], axis=1)\n",
    "    '''\n",
    "    print('SHOWS')\n",
    "    print(shows)\n",
    "    print('ADS')\n",
    "    print(ads[['index', 'Weekdays']])\n",
    "    print(len(adtimes))\n",
    "    '''\n",
    "    ## Expand each ad buy listing to individual spots\n",
    "    return ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/andrew/F08C9B848C9B444E/analysis/tv/ocrtest/KMSB Order 1592727 AZ EDUCATION PROJECT 4.28-4.29.18.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Weekdays</th>\n",
       "      <th>Spots/Week</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>04/23/18</td>\n",
       "      <td>04/29/18</td>\n",
       "      <td>------1</td>\n",
       "      <td>1</td>\n",
       "      <td>$4500</td>\n",
       "      <td>000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>04/23/18</td>\n",
       "      <td>04/29/18</td>\n",
       "      <td>------1</td>\n",
       "      <td>1</td>\n",
       "      <td>$22500</td>\n",
       "      <td>000</td>\n",
       "      <td>LocalNews@9pSu9:00PM-10:00PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>04/23/18</td>\n",
       "      <td>04/29/18</td>\n",
       "      <td>-----1-</td>\n",
       "      <td>1</td>\n",
       "      <td>$17500</td>\n",
       "      <td>000</td>\n",
       "      <td>LocalNews@9pSa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StartDate   EndDate Weekdays Spots/Week    Rate Rating  \\\n",
       "0  04/23/18  04/29/18  ------1          1   $4500    000   \n",
       "1  04/23/18  04/29/18  ------1          1  $22500    000   \n",
       "2  04/23/18  04/29/18  -----1-          1  $17500    000   \n",
       "\n",
       "                        Program  \n",
       "0                                \n",
       "1  LocalNews@9pSu9:00PM-10:00PM  \n",
       "2                LocalNews@9pSa  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/andrew/F08C9B848C9B444E/analysis/tv/ocrtest/KTTU Order 1652036 SINEMA FOR SENATE 9.6-9.12.18.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Weekdays</th>\n",
       "      <th>Spots/Week</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>09/03/18</td>\n",
       "      <td>09/09/18</td>\n",
       "      <td>---TF--</td>\n",
       "      <td>2</td>\n",
       "      <td>$1000</td>\n",
       "      <td>000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>09/10/18</td>\n",
       "      <td>09/16/18</td>\n",
       "      <td>M-W----</td>\n",
       "      <td>2</td>\n",
       "      <td>$1000</td>\n",
       "      <td>0,00</td>\n",
       "      <td>1-2pM-FM-F1p-2p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>09/10/18</td>\n",
       "      <td>09/16/18</td>\n",
       "      <td>===</td>\n",
       "      <td>1</td>\n",
       "      <td>$2000</td>\n",
       "      <td>000</td>\n",
       "      <td>2-3pM-FM-F2p-3p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>09/03/18</td>\n",
       "      <td>09/09/18</td>\n",
       "      <td>---TF--</td>\n",
       "      <td>2</td>\n",
       "      <td>$15000</td>\n",
       "      <td>000</td>\n",
       "      <td>6-630pM-FM-F6p-630p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>09/03/18</td>\n",
       "      <td>09/09/18</td>\n",
       "      <td>~~TF--</td>\n",
       "      <td>2</td>\n",
       "      <td>$15000</td>\n",
       "      <td>000</td>\n",
       "      <td>630-7pM-F6:30PM-7:00PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>09/10/18</td>\n",
       "      <td>09/16/18</td>\n",
       "      <td>MTW---—</td>\n",
       "      <td>3</td>\n",
       "      <td>$15000</td>\n",
       "      <td>000</td>\n",
       "      <td>630-7pM-FM-F630p-7p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>09/03/18</td>\n",
       "      <td>09/09/18</td>\n",
       "      <td>-----1-</td>\n",
       "      <td>1</td>\n",
       "      <td>$10000</td>\n",
       "      <td>000</td>\n",
       "      <td>6-630pSa6:00PM-6:30PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>09/03/18</td>\n",
       "      <td>og/09/18</td>\n",
       "      <td>-----1-</td>\n",
       "      <td>1</td>\n",
       "      <td>$10000</td>\n",
       "      <td>000</td>\n",
       "      <td>630-7pSaSa630p-7p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>09/03/18</td>\n",
       "      <td>09/09/18</td>\n",
       "      <td>------1</td>\n",
       "      <td>1</td>\n",
       "      <td>$10000</td>\n",
       "      <td>000</td>\n",
       "      <td>6-630pSuSu6p-630p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>09/03/18</td>\n",
       "      <td>09/09/18</td>\n",
       "      <td>------1</td>\n",
       "      <td>1</td>\n",
       "      <td>$10000</td>\n",
       "      <td>000</td>\n",
       "      <td>630-7pSuSu630p-7p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>09/03/18</td>\n",
       "      <td>09/09/18</td>\n",
       "      <td>---TF--</td>\n",
       "      <td>2</td>\n",
       "      <td>$3000</td>\n",
       "      <td>000</td>\n",
       "      <td>9-10pM-FM-F9p-10p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>09/10/18</td>\n",
       "      <td>09/16/18</td>\n",
       "      <td>lemme</td>\n",
       "      <td>1</td>\n",
       "      <td>$3000</td>\n",
       "      <td>000</td>\n",
       "      <td>9-10pM-FM-F9p-10p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>09/03/18</td>\n",
       "      <td>O9/09/18</td>\n",
       "      <td>---~~-1</td>\n",
       "      <td>4</td>\n",
       "      <td>$1000</td>\n",
       "      <td>000</td>\n",
       "      <td>11p-12aSuSu11p-12a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StartDate   EndDate Weekdays Spots/Week    Rate Rating  \\\n",
       "0   09/03/18  09/09/18  ---TF--          2   $1000    000   \n",
       "1   09/10/18  09/16/18  M-W----          2   $1000   0,00   \n",
       "2   09/10/18  09/16/18      ===          1   $2000    000   \n",
       "3   09/03/18  09/09/18  ---TF--          2  $15000    000   \n",
       "4   09/03/18  09/09/18   ~~TF--          2  $15000    000   \n",
       "5   09/10/18  09/16/18  MTW---—          3  $15000    000   \n",
       "6   09/03/18  09/09/18  -----1-          1  $10000    000   \n",
       "7   09/03/18  og/09/18  -----1-          1  $10000    000   \n",
       "8   09/03/18  09/09/18  ------1          1  $10000    000   \n",
       "9   09/03/18  09/09/18  ------1          1  $10000    000   \n",
       "10  09/03/18  09/09/18  ---TF--          2   $3000    000   \n",
       "11  09/10/18  09/16/18    lemme          1   $3000    000   \n",
       "12  09/03/18  O9/09/18  ---~~-1          4   $1000    000   \n",
       "\n",
       "                   Program  \n",
       "0                           \n",
       "1          1-2pM-FM-F1p-2p  \n",
       "2          2-3pM-FM-F2p-3p  \n",
       "3      6-630pM-FM-F6p-630p  \n",
       "4   630-7pM-F6:30PM-7:00PM  \n",
       "5      630-7pM-FM-F630p-7p  \n",
       "6    6-630pSa6:00PM-6:30PM  \n",
       "7        630-7pSaSa630p-7p  \n",
       "8        6-630pSuSu6p-630p  \n",
       "9        630-7pSuSu630p-7p  \n",
       "10       9-10pM-FM-F9p-10p  \n",
       "11       9-10pM-FM-F9p-10p  \n",
       "12      11p-12aSuSu11p-12a  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/andrew/F08C9B848C9B444E/analysis/tv/ocrtest/KTTU Order 1675477 SINEMA FOR SENATE 10.12-10.15.18.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Weekdays</th>\n",
       "      <th>Spots/Week</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10/08/18</td>\n",
       "      <td>10/14/18</td>\n",
       "      <td>----1--</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$65000</td>\n",
       "      <td>000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10/15/18</td>\n",
       "      <td>10/21/18</td>\n",
       "      <td>teseeee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1$65000</td>\n",
       "      <td>000</td>\n",
       "      <td>6-630pM-FM-F6p-630p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10/08/18</td>\n",
       "      <td>10/14/18</td>\n",
       "      <td>----1--</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$65000</td>\n",
       "      <td>000</td>\n",
       "      <td>630-7pM-FM-F630p-7p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10/08/18</td>\n",
       "      <td>10/14/18</td>\n",
       "      <td>-----1-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$40000</td>\n",
       "      <td>000</td>\n",
       "      <td>6-630pSa6:00PM-6:30PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10/08/18</td>\n",
       "      <td>10/1418</td>\n",
       "      <td>-----1-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$40000</td>\n",
       "      <td>000</td>\n",
       "      <td>630-7pSaSa630p-7p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10/08/18</td>\n",
       "      <td>10/1418</td>\n",
       "      <td>------1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$40000</td>\n",
       "      <td>000</td>\n",
       "      <td>6-630pSuSu6p-630p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10/08/18</td>\n",
       "      <td>10/1418</td>\n",
       "      <td>------1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$40000</td>\n",
       "      <td>000</td>\n",
       "      <td>630-7pSuSu630p-7p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10/15/18</td>\n",
       "      <td>10/21/18</td>\n",
       "      <td>]------</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$20000</td>\n",
       "      <td>000</td>\n",
       "      <td>MonPrimeB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StartDate   EndDate Weekdays Spots/Week     Rate Rating  \\\n",
       "0  10/08/18  10/14/18  ----1--        NaN   $65000    000   \n",
       "1  10/15/18  10/21/18  teseeee        NaN  1$65000    000   \n",
       "2  10/08/18  10/14/18  ----1--        NaN   $65000    000   \n",
       "3  10/08/18  10/14/18  -----1-        NaN   $40000    000   \n",
       "4  10/08/18   10/1418  -----1-        NaN   $40000    000   \n",
       "5  10/08/18   10/1418  ------1        NaN   $40000    000   \n",
       "6  10/08/18   10/1418  ------1        NaN   $40000    000   \n",
       "7  10/15/18  10/21/18  ]------        NaN   $20000    000   \n",
       "\n",
       "                 Program  \n",
       "0                         \n",
       "1    6-630pM-FM-F6p-630p  \n",
       "2    630-7pM-FM-F630p-7p  \n",
       "3  6-630pSa6:00PM-6:30PM  \n",
       "4      630-7pSaSa630p-7p  \n",
       "5      6-630pSuSu6p-630p  \n",
       "6      630-7pSuSu630p-7p  \n",
       "7              MonPrimeB  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parseCyclePDFs(cyc, basepath, test):\n",
    "    fulladlist = pd.DataFrame(columns=['Date', 'Rate', 'Committee', 'Station', 'Program'])\n",
    "    pdfResults = pd.DataFrame(columns=['Path', 'Result'])\n",
    "    kw = pd.read_csv('/media/andrew/F08C9B848C9B444E/analysis/tv/fccscraper/keys/filetypekeywords.csv') # keywords\n",
    "    malads = pd.DataFrame(columns=['StartDate', 'EndDate', 'Weekdays',\n",
    "                                   'Spots/Week', 'Rate', 'Rating'])\n",
    "    def digToNextLevel(folderpath, name):\n",
    "        nonlocal pdfResults\n",
    "        nonlocal fulladlist\n",
    "        nonlocal kw\n",
    "        adtimes = [] # Final add array\n",
    "        stationads = pd.DataFrame(columns=['StartDate', 'EndDate', 'Weekdays',\n",
    "                                           'Spots/Week', 'Rate', 'Rating'])\n",
    "        def expandDays(x):\n",
    "            adStartDate = datetime.strptime(x['StartDate'], '%m%d%y')\n",
    "            # Test if adbuy string is malformed.\n",
    "            for i, day in enumerate(x['Weekdays']):\n",
    "                if(day!='-'):\n",
    "                    if(day.isdigit()):\n",
    "                        for j in range(0, int(day)):\n",
    "                            adtimes.append({\n",
    "                                        'Date': (adStartDate + timedelta(days=i)),  \n",
    "                                        'Rate': x['Rate'],\n",
    "                                        'Committee': name,\n",
    "                                        'Station': station,\n",
    "                                        'Program': x['Program']\n",
    "                                       })\n",
    "                    else: ## CODE FOR MTW NOTATION\n",
    "                        adtimes.append({\n",
    "                                        'Date': (adStartDate + timedelta(days=i)),  \n",
    "                                        'Rate': x['Rate'],\n",
    "                                        'Committee': name,\n",
    "                                        'Station': station,\n",
    "                                        'Program': x['Program']\n",
    "                                       })\n",
    "        def classifyReportFormat(res, kw):\n",
    "            # Process the scraped text\n",
    "            res = res.split('\\n')\n",
    "            res = [x.replace(' ', '') for x in res ]\n",
    "            res = [x.replace(':', '') for x in res ]\n",
    "            res = [x.replace('.', '') for x in res ]\n",
    "            res = list(filter(lambda a: a != '', res))\n",
    "            res = res[0:200]\n",
    "            res = list(set(res))\n",
    "            # Generate keys from csv and score based on keys\n",
    "            keyAr = kw['pdftype'].values\n",
    "            ptypes = {}\n",
    "            for pt in keyAr:\n",
    "                ptkw = kw[kw['pdftype']==pt]\n",
    "                ptypes[pt] = len(ptkw[ptkw['keyword'].isin(res)])\n",
    "                ptypes[pt] = ptypes[pt]/len(ptkw)\n",
    "            maxVal = max(ptypes, key=ptypes.get)\n",
    "            if ptypes[maxVal] > .2:\n",
    "                return maxVal\n",
    "            else:\n",
    "                return False\n",
    "        def checkIntegrity(ad): # Checks ads are in valid format, performs common corrections due to OCR errors.\n",
    "            nonlocal stationads\n",
    "            malformed=False\n",
    "            # Date\n",
    "            for d in ['StartDate', 'EndDate']:\n",
    "                ad[d] = ad[d].replace('/', '')\n",
    "                ad[d] = ad[d].replace('o', '0')\n",
    "                ad[d] = ad[d].replace('O', '0')\n",
    "                ad[d] = ad[d].replace('g', '9')\n",
    "                try:\n",
    "                    datetime.strptime(ad[d], '%m%d%y')\n",
    "                except:\n",
    "                    malformed=True            \n",
    "            # Rate\n",
    "            ad['Rate'] = ad['Rate'].split('$')[1]\n",
    "            ad['Rate'] = ad['Rate'].replace(',','')\n",
    "            try:\n",
    "                ad['Rate'] = float(ad['Rate'])\n",
    "                ad['Rate'] = ad['Rate']/100\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                malformed=True\n",
    "            # Weekday\n",
    "            validDateChars=['M', 'T', 'W', 'h', 'F', 'S', 'a', 'u', 'H', 'A', 'U']\n",
    "            if len(ad['Weekdays']) != 7:\n",
    "                malformed=True\n",
    "            for char in ad['Weekdays']:\n",
    "                if char.isalpha():\n",
    "                    if char not in validDateChars:\n",
    "                        malformed=True\n",
    "            if malformed!=True:\n",
    "                stationads = stationads.append(ad, ignore_index=True, sort=False)\n",
    "            # Maybe malformed sheet else?\n",
    "        def processPDF(item, station, name):\n",
    "            nonlocal pdfResults\n",
    "            nonlocal fulladlist\n",
    "            nonlocal stationads\n",
    "            pdfProcessors = {'orders': processOrder, 'contracts': processOrder}\n",
    "            result = subprocess.run(['pdftotext', item.path, '-'], \n",
    "                                        stdout=subprocess.PIPE).stdout.decode()\n",
    "\n",
    "            if((len(result.split('\\n')[0:30])> 5)):\n",
    "                reportFormat = classifyReportFormat(result, kw)\n",
    "                if (reportFormat != False) & (reportFormat in pdfProcessors != False) :\n",
    "                    print(item.path)\n",
    "                    pdfTable = convertPDFToTable(item.path)\n",
    "                    try:\n",
    "                        ads = pdfProcessors[reportFormat](pdfTable, name, station)\n",
    "                        display(ads)\n",
    "                        if len(ads) > 0:\n",
    "                            ads.apply(checkIntegrity, axis=1)\n",
    "                            pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                                            'Result': reportFormat+' Success'}, ignore_index=True, sort=False)\n",
    "                        else:\n",
    "                            pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                            'Result': reportFormat+' Scraping Error'}, ignore_index=True)\n",
    "                    except:\n",
    "                        traceback.print_exc()\n",
    "                        pdfResults = pdfResults.append({'Path': item.path, \n",
    "                                            'Result': 'Scraping Error'}, ignore_index=True)\n",
    "                else:\n",
    "                    if reportFormat != False:\n",
    "                        pdfResults = pdfResults.append({'Path': item.path, \n",
    "                           'Result': reportFormat+'No parser written for file.'}, ignore_index=True)\n",
    "                    else:\n",
    "                        pdfResults = pdfResults.append({'Path': item.path, \n",
    "                           'Result': 'No parser written for file.'}, ignore_index=True)\n",
    "            else:\n",
    "                print('OCR')\n",
    "                ocrmypdf.ocr(item.path, item.path, deskew=True, rotate_pages=True)\n",
    "                processPDF(item, station, name)\n",
    "        for item in list(os.scandir(folderpath)):\n",
    "            if (item.is_file()):\n",
    "                processPDF(item, station, name)\n",
    "            else:\n",
    "                digToNextLevel(item.path, item.name)\n",
    "        if len(stationads)>0:\n",
    "            stationads = stationads.drop_duplicates() # subset array arg to ignore columns\n",
    "            stationads.apply(expandDays, axis=1)\n",
    "            fulladlist = fulladlist.append(pd.DataFrame(adtimes), ignore_index=True)\n",
    "    if test:\n",
    "        station = 'test'\n",
    "        digToNextLevel(basepath, cyc)\n",
    "    else:\n",
    "        for station in list(os.scandir(basepath)):\n",
    "            station = station.name\n",
    "            cyclepath = basepath+station+'/Political Files/'+cyc+'/'\n",
    "            digToNextLevel(cyclepath, cyc)\n",
    "        fulladlist['Cycle'] = cyc\n",
    "    return {'ads': fulladlist, 'pdfs': pdfResults, 'malformedads': malads}\n",
    "results = parseCyclePDFs('2018', '/media/andrew/F08C9B848C9B444E/analysis/tv/ocrtest', test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>27 AZ EDUCATION PROJECT 4.28-4.29.18.pdf</td>\n",
       "      <td>orders Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>652036 SINEMA FOR SENATE 9.6-9.12.18.pdf</td>\n",
       "      <td>orders Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>477 SINEMA FOR SENATE 10.12-10.15.18.pdf</td>\n",
       "      <td>orders Success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Path          Result\n",
       "0  27 AZ EDUCATION PROJECT 4.28-4.29.18.pdf  orders Success\n",
       "1  652036 SINEMA FOR SENATE 9.6-9.12.18.pdf  orders Success\n",
       "2  477 SINEMA FOR SENATE 10.12-10.15.18.pdf  orders Success"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['pdfs']['Path'] = results['pdfs']['Path'].str[-40:]\n",
    "results['pdfs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48 entries, 0 to 47\n",
      "Data columns (total 5 columns):\n",
      "Date         48 non-null datetime64[ns]\n",
      "Rate         48 non-null float64\n",
      "Committee    48 non-null object\n",
      "Station      48 non-null object\n",
      "Program      48 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "results['ads'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Committee</th>\n",
       "      <th>Station</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Rate, Committee, Station, Program]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['ads'][results['ads']['Program'].str.contains('Prime')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62393"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocrmypdf.ocr('input.pdf', 'output.pdf', deskew=True, rotate_pages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "9\n",
      "6\n",
      "['Weekdays', 'StartDateEndDate', 'LengthWeek', 'Spots/', 'OriginalDate/Revision', 'PrintDate', 'Product1/2', 'Amount', 'AdvertiserCode', 'Start/End', 'Cash/Trade', 'Contract/Revision', 'Spots/Week']\n",
      "['BillingAddress', 'Deal#', 'Invoice#', 'AgencyRef', 'Order#', 'Property', 'Product', 'AdvertiserRef']\n",
      "['#Spots', 'OriginalDate/Rev', 'Estimate', 'Demographic', 'OrderSeparation', 'ORDER', 'PrimaryAE', 'BillPlan', 'Priority', 'UnitCode', 'Agency', 'GrossAmount', 'BillingCalendar', 'ProductCodes', 'Advertiser', 'FlightDates', 'Order%', 'Order/Rev', 'StartDate/EndDate', 'OrderType', 'AdvertiserExternalID', 'AccountExecutives', 'Month', 'BillingCycle', 'EOM/EOC', 'InventoryCode', 'BillingType', 'Start', 'Orders', 'AltOrder#', 'AgencyExternalID', 'RevenueCode2', 'AgencyCommission', 'Totals', 'SalesOffice', 'RevenueCode3', 'StartDate', 'SalesRegion', 'NewBusinessThru', 'BillingContact', 'NetAmount', 'AccountExecutive', 'RevenueCode1', '#SpotsGrossAmount', 'BuyingContact', 'ProductDesc', 'EndDate', 'Rating', 'General', 'Broadcast']\n"
     ]
    }
   ],
   "source": [
    "# Generating keys for predicting what form a PDF is in.\n",
    "keys = {}\n",
    "for ftype in list(os.scandir('/media/andrew/F08C9B848C9B444E/analysis/tv/orderscoring/')):\n",
    "    o = list(os.scandir('/media/andrew/F08C9B848C9B444E/analysis/tv/orderscoring/'+ftype.name+'/'))\n",
    "    op = []\n",
    "    # Convert all pdfs to text, string process them and turn them into an array of strings\n",
    "    for f in o:\n",
    "        res = subprocess.run(['pdftotext', f.path, '-'], \n",
    "                                            stdout=subprocess.PIPE).stdout.decode()\n",
    "        res = res.split('\\n')\n",
    "        res = [x.replace(' ', '') for x in res ]\n",
    "        res = [x.replace(':', '') for x in res ]\n",
    "        res = [x.replace('.', '') for x in res ]\n",
    "        res = list(filter(lambda a: a != '', res))\n",
    "        res = res[0:200]\n",
    "        res = list(set(res))\n",
    "        #print(res[0:100])\n",
    "        if len(res)>1:\n",
    "            op.append(res)\n",
    "        else:\n",
    "            ocrmypdf.ocr(f.path, f.path, deskew=True, rotate_pages=True)\n",
    "    curSet = []\n",
    "    # Filter so only keys that exist in all files of the given report format remain.\n",
    "    print(len(op))\n",
    "    for l in op:\n",
    "        if len(curSet)==0:\n",
    "            curSet=l\n",
    "        else:\n",
    "            curSet = [x for x in curSet if x in l]\n",
    "    keys[ftype.name] = curSet\n",
    "# Filter out keys that are non-unique to that report type.\n",
    "for k in keys:\n",
    "    types = ['contracts', 'invoices', 'orders']\n",
    "    types = [x for x in types if x != k]\n",
    "    for t in types:\n",
    "        keys[k] = [x for x in keys[k] if x not in keys[t]]\n",
    "    # Get rid of nonspecific keys\n",
    "    keys[k] = list(filter(lambda a: (len(a)>4) & (len(a)<23) , keys[k]))\n",
    "    print(keys[k])\n",
    "keys = [[(k, vv) for vv in v] for k, v in keys.items()]\n",
    "keys2 = []\n",
    "for k in keys:\n",
    "    for v in k:\n",
    "        keys2.append(v)\n",
    "keys = pd.DataFrame(keys2, columns=['pdftype', 'keyword'])\n",
    "keys.to_csv('filetypekeywords.csv', index=False)\n",
    "#print(curSet)\n",
    "#print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('—')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
